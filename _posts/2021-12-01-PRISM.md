# PRISM: Rethinking the RDMA Interface for Distributed Systems

## 摘要

远程直接内存访问(Remote Direct Memory Access，RDMA)通过提供对远程主机内存的低延迟、绕过cpu的访问，已被用于加速各种分布式系统。然而，在这些系统中使用的大多数分布式协议都不能很容易地用RDMA提供的简单的内存读和写来表示。因此，设计人员面临一个选择，要么引入额外的协议复杂性(例如，额外的往返行程)，要么完全放弃RDMA的好处。

本文认为对RDMA接口的扩展可以解决这一困境。我们介绍PRISM接口，它添加了四个新的原语:indirection、allocation、enhanced-CAS、operation chaining。这些增加了RDMA接口的表现力，同时仍然可以使用相同的底层硬件特性实现。我们通过设计三个使用PRISM原语的新应用程序来展示它们的实用性，这些应用程序几乎不需要服务器端CPU的参与:(1)PRISM- kv，键值存储;(2) PRISM-RS，一个复制的块存储;(3) PRISM-TX，分布式事务协议。通过使用PRISM原语的基于软件的实现，我们证明了这些系统优于之前基于rdma的等效系统。

## 1. 引言

远程直接内存访问(RDMA)已迅速成为数据中心系统中实现高吞吐量和低延迟的不可或缺的工具之一。随着网络带宽相对于CPU速度的不断增加，降低数据包处理的CPU成本变得至关重要。这使得RDMA,它提供了一个标准,加速一个主机接口直接访问另一个主机的内存：硬件RDMA实现完全绕过主机CPU[28],甚至软件实现提供显著的性能改进,简化了网络堆栈和减少上下文切换开销[26]。

大量的文献探讨了如何重新设计分布式系统以使用RDMA通信[6,10,14,31,44]。一个常见的主题是，使应用程序在RDMA上运行需要进行复杂且昂贵的修改。这种复杂性的根源在于RDMA接口本身：很少有分布式应用程序能够轻易地用简单的远程内存读写操作来表达它们的逻辑。因此，许多RDMA应用程序被迫添加额外的操作，即额外的网络往返，以牺牲一些延迟优势[10,31,32]。其他的使用混合设计，要求应用程序CPU参与一些操作[10,31,43]-或者，在某些情况下，仅仅使用RDMA来实现更快的消息传递协议[15,34]-这否定了CPU旁路的好处。

本文认为，超越基本的RDMA接口是实现构建低延迟系统的网络加速的全部潜力的必要条件。RDMA接口最初是为了支持并行超级计算应用而设计的，它无法满足当今分布式系统的需求。我们展示了通过使用一些额外的原语扩展接口，就可以完全使用远程操作实现复杂的分布式应用程序，比如复制存储。

我们在这篇文章中的目标是确定一组通用的(即非应用特定的)RDMA接口扩展，允许分布式系统更好地利用RDMA硬件的低延迟和CPU卸载能力。我们的提案是PRISM接口。PRISM用另外四个原语扩展了RDMA读/写接口：indirection、allocation、enhanced-CAS、operation chaining。结合起来，它们支持常见的远程访问模式，如数据结构导航、错位更新和并发控制。我们认为PRISM API非常简单，可以在RDMA NIC中实现，因为它重用了现有的微架构机制。我们还在基于软件的原型网络堆栈中实现PRISM接口，该网络堆栈使用专用CPU核心实现远程操作，其灵感来自谷歌的SNAP网络堆栈[26]所采取的方法。

我们通过三个常见分布式应用程序的案例研究来演示PRISM API的优点。第一个是键值存储，它演示了PRISM可用于读取和操作远程数据结构，将读取延迟降低到Pilaf[31]的75%，尽管我们的原型使用软件模拟单边操作。第二种是复制块存储，通过使用CAS和间接操作来实现ABD仲裁协议[4]，提供容错存储，与传统的基于锁的方法[44]相比，提供了50%的吞吐量改进，尽管使用专用的CPU内核来实现单边操作。第三种是事务性键值存储，它在分片存储系统上提供了强大的原子性保证。它的新协议使用CAS和间接操作，仅使用两次往返就提交事务。这使吞吐量比FaRM[10]提高了20%，同时减少了18%的延迟。

综上所述，本文做出了以下贡献：
- 我们证明了现有的RDMA接口为分布式系统带来了额外的协议复杂性。
- 我们引入了PRISM接口，它通过额外的原语扩展了RDMA，以支持分布式应用程序中的常见模式。
- 我们展示了三个复杂的应用程序——键值存储、复制块存储和分布式事务——可以完全使用PRISM接口实现。
- 我们构建了PRISM接口的基于软件的原型，并展示了尽管与NIC相比它有额外的性能开销，但在PRISM之上构建的应用程序实现了延迟和吞吐量方面的好处。

## 2. 背景和动机

RDMA是一个广泛部署的网络接口[13,26]，它允许远程客户端直接在远程主机上读或写内存，完全绕过远程CPU。

### 2.1 RPCs vs内存访问：RDMA的困境

RDMA提供两种类型的操作。双边操作具有传统的消息传递语义。一个SEND操作将消息发送给调用receive的远程应用程序。单边操作允许主机在远程主机上(在预先注册的区域)读或写内存。

在系统界，关于是使用单边操作还是双面操作的争论相当激烈[16,19,43]。单边操作更快，CPU效率更高，但仅限于简单的读写操作。双面消息传递，因为它允许在两端进行处理，可以产生一个整体上更快的系统，即使通信操作本身较慢。

要了解这种权衡是如何进行的，可以考虑例如Pilaf[31]，一个早期的基于rdma的键值存储。Pilaf将指向键值对象的指针存储在哈希表中，而实际数据存储在单独的区段结构中。这两种结构都是通过RDMA公开的，因此客户端可以通过远程读取哈希表来执行键-值查找，然后使用指针远程读取区段存储。这不需要服务器端CPU的参与，但是需要两次往返。使用双边操作构建的传统键值存储实现只需要一次往返，但每个操作都涉及CPU。

那么，系统设计人员的困境是，是在读写操作之外构建更复杂的协议，还是在消息传递方面构建更简单的协议？换句话说，是执行两个(或多个)单边RDMA操作更快，还是执行单个RPC更快?在RDMA的早期，选择是明确的：RDMA操作比RPC快20倍[31]。由于后续工作极大地降低了双向RPC的成本[16,19]，并且RDMA已经部署在具有更高延迟的大规模设置中[12,13]，使用哪一种的问题要复杂得多。

为了理解当前的权衡，我们在两台使用40GB以太网连接的服务器上测量单边RDMA操作与使用eRPC[16]实现的双边RPC的性能(4.3节描述细节)。使用单边读取完成512字节值的读取大约需要3.2us，比使用双面RPC快43% (5.6us)。但这意味着，像上面的例子一样，一个单边读的系统比一个纯软件实现慢0.8us。因此，单边RDMA操作只有在不需要更复杂的协议时才会提供性能优势。

### 2.2 后RDMA系统的原则

大多数关于RDMA系统的工作都假设我们被限制在当前的RDMA读/写接口。如果我们可以扩展RDMA接口呢?硬件供应商[29]和软件实现[26]以一种特别的方式添加了各种新的操作。在本文中，我们后退一步，询问需要哪些新功能来支持直接在RDMA上运行的分布式系统，而不需要CPU参与或额外的往返行程。

**导航数据结构**：当大小和位置已知时，RDMA支持远程读取。大多数应用程序，如Pilaf，使用更复杂的数据结构来构建索引，存储变长对象，并帮助处理并发更新。遍历这些结构需要多次RDMA读取。能够在指针上执行间接操作可以消除一些往返。

**支持异地更新**：修改远程数据结构尤其具有挑战性，因为读取操作可能同时发生。为了避免随之而来的一致性问题，许多系统[10,31,32]只从服务器CPU执行写操作。我们的目标是构建能够使用RDMA操作同时处理读写的系统。为此，我们提倡一种设计模式，将新数据写入到一个单独的缓冲区中，然后自动更新指针以从旧值交换到新值——这种方法类似于并发编程中的read-copy-update[27]。要实现这一点，需要新的RDMA支持，将数据写入新的缓冲区，并自动更新指向其位置的指针。

**乐观并发控制**：对复杂数据结构的更新需要同步。虽然现在可以使用RDMA来实现锁[44,45]，但性能损失可能很大。扩展RDMA的比较和交换功能将允许我们实现复杂的、基于版本的乐观并发控制[21]，这种方法很适合我们的异地更新方法。

**链式操作**：一个常见的主题是应用程序需要执行复合操作，其中后一个操作的参数取决于前一个操作的结果——先读取一个指针，然后读取它所指向的值，或写入一个对象，然后交换指针。现在，这需要将中间结果返回给客户机，并执行一个新的操作——以及另一个网络往返。如果我们有一种方法将操作链接起来，使一个操作依赖于另一个操作，但仍然在一个往返行程中执行它们，就可以避免这种开销。

### 2.3 扩展接口的案例

可以通过以各种方式扩展RDMA接口来解决上一节的原则。在本文中，我们论证了一组简单的、通用的扩展可以用于各种应用程序。使用简单的操作可以实现和部署这些扩展。

另一种方法是允许应用程序提供在远程主机上运行的自己的代码，即将自定义应用程序逻辑部署到智能网卡[3,37]。虽然这种方法很强大，但它在部署方面存在相当大的挑战。通过与部署了智能网卡的云提供商对话，即使在单租户环境中，推出智能网卡更新也是一项挑战，因为它涉及到主机上运行的所有东西的停机时间。允许多租户环境中的用户提供自己的代码带来了主要的安全性和性能隔离挑战[22,41]。

相反，我们主张一组简单的泛型原语。这样简单的扩展可能对更多的应用程序有用，无论是当前的还是未来的。这里的简单性也有助于实现：我们认为我们提出的原语可以添加到基于软件的网络堆栈、可重新配置的智能网卡，甚至可以添加到未来的固定功能网卡。本文的其余部分提出了这样的一般扩展，并演示了它们对于一般应用程序是有用的。

## PRISM接口

为了解决使用RDMA构建分布式系统的固有挑战，我们提出了一个扩展网络接口PRISM(用于与系统内存远程交互的原语)。PRISM为现有的RDMA接口增加了四个额外特性。这些设计是为了支持我们在实现分布式协议时观察到的常见模式。

PRISM的接口是围绕三个原则设计的:(1)通用性——它们不应该编码特定于应用程序的功能;(2)界面复杂度最小;(3)最小的实现复杂性，实现了快速、可预测的性能，便于在各种平台上实现，包括未来的NIC ASICs。

遵循这些原则，我们以四种方式扩展RDMA接口。表1提供了PRISM API的摘要。

![](/images/PRISM/PRISM_primitives.png)

### 3.1 indirect操作

许多RDMA应用程序需要遍历远程数据结构。这些结构在许多方面使用间接：提供索引，支持可变长度数据，等等。目前，追逐指针需要额外的往返。

PRISM允许read、write和比较与交换(CAS)操作接受间接参数。这些操作的目标地址可以被解释为指向实际目标的指针的地址。此外，用于write或cas操作的数据可以从服务器端内存位置读取，而不是从RDMA请求本身读取。

对于read和write，目标可以被选择解释为一个⟨ptr,bound⟩结构。在这种情况下，操作的长度被限制为客户端请求的长度和边界的较小值。这支持变长对象:客户机可以执行大长度读取，但只接收实际存储的数据。

PRISM中的间接操作重用了现有的RDMA安全机制，这些机制确保远程客户端只能在被授予访问权限的主机内存区域上操作。为了通过间接操作访问内存区域，客户端必须包含主机在该区域第一次注册到NIC时生成的密钥。如果目标地址或目标地址所指向的位置在具有不同rkey的内存区域中(或者根本没有注册)，该操作将被主机拒绝。

### 3.2 内存分配

修改数据结构对于现有的RDMA接口来说尤其具有挑战性：必须将对象写入固定的、预先分配的内存区域，这使得处理大小可变的对象或位置不正确的更新变得困难。需要的是一个内存分配原语。PRISM提供了一个，它分配一个缓冲区并返回指向其位置的指针。

为了使用PRISM的分配原语，服务器端进程向NIC注册(RDMA术语为“post”)一个缓冲区队列。当NIC从远程主机接收到一个ALLOCATE请求时，它从这个空闲列表弹出一个缓冲区，将提供的数据写入缓冲区，并使用地址进行响应。这个操作与PRISM的请求链接机制结合起来特别强大，下面将讨论这个机制：PRISM客户机可以分配一个缓冲区，向它写入数据，然后在另一个数据结构中安装指向它的指针(通过CAS)。

PRISM在网卡(或软件网络栈)数据平面上进行内存分配。然而，内存注册是由服务器CPU完成的。这是必要的，因为注册内存需要与内核交互，以识别相应的物理地址和固定缓冲区。因为涉及到服务器CPU，所以对于应用程序重用这些缓冲区的正确性至关重要，因为只有当并发网卡操作完成时，回收的缓冲区才会被添加回空闲列表。虽然这只是将同步NIC和服务器CPU的负担转移到原语的实现上，但重要的是将这种同步移出了应用程序的常规路径。

管理客户端分配的内存可能具有挑战性;对于通过远程访问修改状态的应用程序来说，这是一个基本的挑战。特定的内存管理策略由应用程序自行决定。本文中的应用程序使用客户端来检测何时不再使用对象，例如，何时替换了以前的版本。它们将未使用的缓冲区报告给一个运行在服务器上的守护进程(通过传统RPC)，后者将其重新注册到NIC的空闲列表中;可以在客户端和服务器端使用批处理来最小化开销。另一种受垃圾收集启发的方法是，让服务器端应用程序代码定期扫描数据结构，以确定可以回收的缓冲区。

我们的分配器故意设计得很简单，只从特定队列中分配第一个可用的缓冲区。我们选择这个而不是一个更复杂的分配器，因为(如§4.2所述)现有的RDMA网卡已经有必要的硬件支持来实现它。结果是，使用整个预分配的缓冲区分配内存会带来空间开销。应用程序可以通过注册包含不同大小缓冲区的多个队列，并选择合适的队列来最小化这种影响。例如，使用大小为2的缓冲区可以保证最大空间开销为2倍。纯软件实现可能会选择使用更复杂的分配器。

